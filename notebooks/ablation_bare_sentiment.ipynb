{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "from analytics.sentiment_analysis import EmailPreprocessor, EnsembleSentimentAnalyzer\n",
    "\n",
    "from config.logger import CustomLogger\n",
    "logger = CustomLogger(name=\"BaseChainAnalyzer\")\n",
    "\n",
    "\n",
    "class BaseChainsAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyzes sentiment of base chains from a JSONL file where each entry contains \n",
    "    a string with multiple emails marked as \"Email 1:\", \"Email 2:\", etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, jsonl_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with the path to the JSONL file.\n",
    "        \n",
    "        Args:\n",
    "            jsonl_path (str): Path to the JSONL file containing base chains\n",
    "        \"\"\"\n",
    "        self.jsonl_path = jsonl_path\n",
    "        logger.info(f\"Loading date from {jsonl_path}...\")\n",
    "        self.df = pd.read_json(jsonl_path, lines=True)\n",
    "        logger.info(f\"Loaded {len(self.df)} email chains\")\n",
    "        \n",
    "        self.preprocessor = EmailPreprocessor()\n",
    "        self.ensemble_analyzer = EnsembleSentimentAnalyzer()\n",
    "        self.results = []\n",
    "        \n",
    "        if \"llama3b\" in jsonl_path.lower():\n",
    "            self.model_name = \"Llama-3B\"\n",
    "        elif \"llama8b\" in jsonl_path.lower():\n",
    "            self.model_name = \"Llama-8B\"\n",
    "        else:\n",
    "            self.model_name = \"Unknown\"\n",
    "        \n",
    "        logger.ok(f\"Detected model: {self.model_name}\")\n",
    "        \n",
    "    def split_email_chain(self, chain_text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Split a chain text containing multiple emails into individual email texts.\n",
    "        \n",
    "        Args:\n",
    "            chain_text (str): The chain text with multiple emails\n",
    "            \n",
    "        Returns:\n",
    "            List[str]: List of individual email texts\n",
    "        \"\"\"\n",
    "        email_pattern = r'(?:<)?Email\\s*\\d+(?:>)?:\\s*'        \n",
    "        emails = re.split(email_pattern, chain_text)\n",
    "\n",
    "        emails = [email.strip() for email in emails if email.strip()]\n",
    "        \n",
    "        return emails\n",
    "    \n",
    "    def process_chain(self, chain_text: str, chain_id: int) -> Dict:\n",
    "        \"\"\"\n",
    "        Process a single email chain and compute its sentiment.\n",
    "        \n",
    "        Args:\n",
    "            chain_text (str): The chain text with multiple emails\n",
    "            chain_id (int): ID for the chain\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Dictionary with sentiment analysis results\n",
    "        \"\"\"\n",
    "                \n",
    "        emails = self.split_email_chain(chain_text)\n",
    "        \n",
    "        processed_emails = []\n",
    "        individual_sentiments = []\n",
    "        \n",
    "        for i, email in enumerate(emails):\n",
    "            processed_email = self.preprocessor.process_email(email)\n",
    "            if processed_email.strip():\n",
    "                processed_emails.append(processed_email)\n",
    "                \n",
    "                sentiment = self.ensemble_analyzer.predict_sentiment(processed_email)\n",
    "                sentiment_result = {\n",
    "                    \"chain_id\": chain_id,\n",
    "                    \"email_index\": i,\n",
    "                    \"model\": self.model_name,\n",
    "                    \"sentiment_neg\": sentiment[\"sentiment_neg\"],\n",
    "                    \"sentiment_neu\": sentiment[\"sentiment_neu\"],\n",
    "                    \"sentiment_pos\": sentiment[\"sentiment_pos\"]\n",
    "                }\n",
    "                individual_sentiments.append(sentiment_result)\n",
    "        \n",
    "        aggregated_text = \" \".join(processed_emails)\n",
    "        if not aggregated_text:\n",
    "            chain_sentiment = {\n",
    "                \"sentiment_neg\": 0.0,\n",
    "                \"sentiment_neu\": 1.0,\n",
    "                \"sentiment_pos\": 0.0\n",
    "            }\n",
    "        else:\n",
    "            chain_sentiment = self.ensemble_analyzer.predict_sentiment(aggregated_text)\n",
    "            \n",
    "        result = {\n",
    "            \"chain_id\": chain_id,\n",
    "            \"model\": self.model_name,\n",
    "            \"num_emails\": len(processed_emails),\n",
    "            \"sentiment_neg\": chain_sentiment[\"sentiment_neg\"],\n",
    "            \"sentiment_neu\": chain_sentiment[\"sentiment_neu\"],\n",
    "            \"sentiment_pos\": chain_sentiment[\"sentiment_pos\"],\n",
    "            \"individual_sentiments\": individual_sentiments\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def analyze_all_chains(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Analyze all chains in the dataframe.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: List of sentiment analysis results for each chain\n",
    "        \"\"\"\n",
    "        self.results = []\n",
    "        \n",
    "        logger.info(f\"Analyzing sentiment for {len(self.df)} chains\")\n",
    "        for i, row in tqdm(self.df.iterrows(), total=len(self.df)):\n",
    "            chain_text = row[\"chain\"]\n",
    "            result = self.process_chain(chain_text, i)\n",
    "            self.results.append(result)\n",
    "            \n",
    "        return self.results\n",
    "    \n",
    "    def save_results(self, output_dir: str = \"output/sentiment_analysis\") -> str:\n",
    "        \"\"\"\n",
    "        Save the analysis results to a JSON file.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str): Directory where results will be saved\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to the saved file\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            self.analyze_all_chains()\n",
    "            \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        model_str = self.model_name.lower().replace('-', '')\n",
    "        filename = f\"sentiment_base_{model_str}.json\"\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        chain_results = []\n",
    "        for result in self.results:\n",
    "            chain_result = {k: v for k, v in result.items() if k != \"individual_sentiments\"}\n",
    "            chain_results.append(chain_result)\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(chain_results, f, indent=2)\n",
    "            \n",
    "        individual_results = []\n",
    "        for result in self.results:\n",
    "            individual_results.extend(result[\"individual_sentiments\"])\n",
    "            \n",
    "        individual_file_path = os.path.join(output_dir, f\"sentiment_base_{model_str}_individual.json\")\n",
    "        with open(individual_file_path, 'w') as f:\n",
    "            json.dump(individual_results, f, indent=2)\n",
    "        \n",
    "        logger.ok(f\"Saved chain results to: {file_path}\")\n",
    "        logger.ok(f\"Saved individual email results to: {individual_file_path}\")\n",
    "            \n",
    "        return file_path\n",
    "    \n",
    "    def get_summary_statistics(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate summary statistics for the sentiment analysis.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Dictionary with summary statistics\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            self.analyze_all_chains()\n",
    "            \n",
    "        sentiment_neg = [r[\"sentiment_neg\"] for r in self.results]\n",
    "        sentiment_neu = [r[\"sentiment_neu\"] for r in self.results]\n",
    "        sentiment_pos = [r[\"sentiment_pos\"] for r in self.results]\n",
    "        \n",
    "        summary = {\n",
    "            \"model\": self.model_name,\n",
    "            \"num_chains\": len(self.results),\n",
    "            \"sentiment_neg_mean\": np.mean(sentiment_neg),\n",
    "            \"sentiment_neg_std\": np.std(sentiment_neg),\n",
    "            \"sentiment_neu_mean\": np.mean(sentiment_neu),\n",
    "            \"sentiment_neu_std\": np.std(sentiment_neu),\n",
    "            \"sentiment_pos_mean\": np.mean(sentiment_pos),\n",
    "            \"sentiment_pos_std\": np.std(sentiment_pos),\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "def analyze_base_chains(jsonl_path, output_dir=\"output/sentiment_analysis\"):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of base chains from a JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path (str): Path to the JSONL file\n",
    "        output_dir (str): Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Summary statistics of the analysis\n",
    "    \"\"\"\n",
    "    analyzer = BaseChainsAnalyzer(jsonl_path)\n",
    "    analyzer.analyze_all_chains()\n",
    "    file_path = analyzer.save_results(output_dir)\n",
    "    summary = analyzer.get_summary_statistics()\n",
    "    return summary"
   ],
   "id": "bb43872323524b71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "jsonl_path_3b = \"../data/email_datasets/synthetic/baserefine/base/llama3b/base_chains.jsonl\"\n",
    "results_3b = analyze_base_chains(jsonl_path_3b, output_dir=\"output/llama3b_sentiment\")"
   ],
   "id": "26570107f92be102",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "jsonl_path_8b = \"../data/email_datasets/synthetic/baserefine/base/llama8b/base_chains.jsonl\"\n",
    "results_8b = analyze_base_chains(jsonl_path_8b, output_dir=\"output/llama8b_sentiment\")"
   ],
   "id": "27ec83d1de21d685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as mtick\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def load_and_process_sentiment_data(method_filepath, base_llama3b, base_llama8b):\n",
    "    \"\"\"\n",
    "    Load and process raw sentiment data from files and calculate averages.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    method_filepath : str\n",
    "        Directory containing sentiment distribution data for refined models\n",
    "    base_llama3b : str\n",
    "        Path to base Llama-3B sentiment data JSON file\n",
    "    base_llama8b : str\n",
    "        Path to base Llama-8B sentiment data JSON file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with calculated sentiment averages\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    base_models = {\n",
    "        'llama3b': base_llama3b,\n",
    "        'llama8b': base_llama8b\n",
    "    }\n",
    "    \n",
    "    for model_key, file_path in base_models.items():\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                base_data = json.load(f)\n",
    "                \n",
    "            df = pd.DataFrame(base_data)\n",
    "            \n",
    "            sentiment_cols = ['sentiment_neg', 'sentiment_neu', 'sentiment_pos']\n",
    "            if all(col in df.columns for col in sentiment_cols):\n",
    "                avg_sentiments = {\n",
    "                    'base_model': model_key,\n",
    "                    'refiner_model': 'base',\n",
    "                    'stage': 'Base',\n",
    "                    'sentiment_neg_avg': df['sentiment_neg'].mean(),\n",
    "                    'sentiment_neu_avg': df['sentiment_neu'].mean(),\n",
    "                    'sentiment_pos_avg': df['sentiment_pos'].mean(),\n",
    "                    'sentiment_neg_std': df['sentiment_neg'].std(),\n",
    "                    'sentiment_neu_std': df['sentiment_neu'].std(),\n",
    "                    'sentiment_pos_std': df['sentiment_pos'].std(),\n",
    "                    'sample_count': len(df)\n",
    "                }\n",
    "                results.append(avg_sentiments)\n",
    "                print(f\"Processed {model_key} base data with {len(df)} samples\")\n",
    "            else:\n",
    "                print(f\"Warning: Missing sentiment columns in {model_key} base data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {model_key} base data: {e}\")\n",
    "    \n",
    "    pattern = os.path.join(method_filepath, \"sentiment_distribution_*.csv\")\n",
    "    distribution_files = glob.glob(pattern)\n",
    "    \n",
    "    for file_path in distribution_files:\n",
    "        try:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            \n",
    "            if 'llama3b' in file_name.lower():\n",
    "                base_model = 'llama3b'\n",
    "            elif 'llama8b' in file_name.lower():\n",
    "                base_model = 'llama8b'\n",
    "            else:\n",
    "                print(f\"Unknown base model in file: {file_name}\")\n",
    "                continue\n",
    "                \n",
    "            for refiner in ['claude', 'deepseek', 'gemini', 'gpt4', 'mistral']:\n",
    "                if refiner in file_name.lower():\n",
    "                    refiner_model = refiner\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Unknown refiner model in file: {file_name}\")\n",
    "                continue\n",
    "            \n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            sentiment_cols = ['sentiment_neg', 'sentiment_neu', 'sentiment_pos']\n",
    "            if all(col in df.columns for col in sentiment_cols):\n",
    "                avg_sentiments = {\n",
    "                    'base_model': base_model,\n",
    "                    'refiner_model': refiner_model,\n",
    "                    'stage': 'Refined',\n",
    "                    'sentiment_neg_avg': df['sentiment_neg'].mean(),\n",
    "                    'sentiment_neu_avg': df['sentiment_neu'].mean(),\n",
    "                    'sentiment_pos_avg': df['sentiment_pos'].mean(),\n",
    "                    'sentiment_neg_std': df['sentiment_neg'].std(),\n",
    "                    'sentiment_neu_std': df['sentiment_neu'].std(),\n",
    "                    'sentiment_pos_std': df['sentiment_pos'].std(),\n",
    "                    'sample_count': len(df)\n",
    "                }\n",
    "                results.append(avg_sentiments)\n",
    "                print(f\"Processed {base_model}_{refiner_model} data with {len(df)} samples\")\n",
    "            else:\n",
    "                print(f\"Warning: Missing sentiment columns in {file_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    results_df['base_model_display'] = results_df['base_model'].apply(\n",
    "        lambda x: 'Llama-3B' if x == 'llama3b' else 'Llama-8B')\n",
    "    \n",
    "    results_df['refiner_model_display'] = results_df['refiner_model'].apply(\n",
    "        lambda x: x.upper() if x.lower() == 'gpt4' else x.title() if x != 'base' else 'Base')\n",
    "    \n",
    "    os.makedirs(\"output/sentiment\", exist_ok=True)\n",
    "    results_df.to_csv(\"../output/sentiment/recomputed_sentiment_averages.csv\", index=False)\n",
    "    print(f\"Saved recomputed sentiment averages to output/sentiment/recomputed_sentiment_averages.csv\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def create_sentiment_visualization(results_df, sentiment_type, color, output_dir=\"output/sentiment\"):\n",
    "    \"\"\"\n",
    "    Creates a side-by-side visualization of sentiment changes between base and refined models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : DataFrame\n",
    "        DataFrame containing sentiment results\n",
    "    sentiment_type : str\n",
    "        Type of sentiment to visualize ('neg', 'pos', or 'neu')\n",
    "    color : str or tuple\n",
    "        Color to use for the bars\n",
    "    output_dir : str\n",
    "        Directory to save the output figures\n",
    "    \"\"\"\n",
    "    sentiment_map = {\n",
    "        'neg': ('sentiment_neg_avg', 'Negative'),\n",
    "        'pos': ('sentiment_pos_avg', 'Positive'),\n",
    "        'neu': ('sentiment_neu_avg', 'Neutral')\n",
    "    }\n",
    "    \n",
    "    column_name, display_name = sentiment_map.get(sentiment_type, sentiment_map['neg'])\n",
    "    \n",
    "    delta_data = []\n",
    "    \n",
    "    for base_model in results_df['base_model_display'].unique():\n",
    "        base_data = results_df[(results_df['base_model_display'] == base_model) & \n",
    "                             (results_df['refiner_model_display'] == 'Base')]\n",
    "        \n",
    "        if base_data.empty:\n",
    "            print(f\"No base data for {base_model}\")\n",
    "            continue\n",
    "        \n",
    "        base_value = base_data[column_name].values[0]\n",
    "        print(f\"{base_model} base {sentiment_type} value: {base_value:.6f}\")\n",
    "        \n",
    "        for refiner in results_df[results_df['refiner_model_display'] != 'Base']['refiner_model_display'].unique():\n",
    "            refined_data = results_df[(results_df['base_model_display'] == base_model) & \n",
    "                                    (results_df['refiner_model_display'] == refiner)]\n",
    "            \n",
    "            if refined_data.empty:\n",
    "                print(f\"No refined data for {base_model} with {refiner}\")\n",
    "                continue\n",
    "            \n",
    "            refined_value = refined_data[column_name].values[0]\n",
    "            delta = refined_value - base_value\n",
    "            \n",
    "            print(f\"{base_model} with {refiner} {sentiment_type}: {refined_value:.6f}, delta: {delta:.6f}\")\n",
    "            \n",
    "            delta_data.append({\n",
    "                'base_model': base_model,\n",
    "                'refiner_model': refiner,\n",
    "                f'delta_{sentiment_type}': delta\n",
    "            })\n",
    "    \n",
    "    delta_df = pd.DataFrame(delta_data)\n",
    "    \n",
    "    if delta_df.empty:\n",
    "        print(f\"No delta data to plot for {display_name} sentiment\")\n",
    "        return None\n",
    "    \n",
    "    rcParams['font.size'] = 10\n",
    "    rcParams['axes.linewidth'] = 0.8\n",
    "    rcParams['axes.spines.top'] = False\n",
    "    rcParams['axes.spines.right'] = False\n",
    "    rcParams['xtick.major.width'] = 0.8\n",
    "    rcParams['ytick.major.width'] = 0.8\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3.5), sharey=True)\n",
    "    \n",
    "    base_models = sorted(delta_df['base_model'].unique())\n",
    "    \n",
    "    delta_col = f'delta_{sentiment_type}'\n",
    "    y_max = delta_df[delta_col].max() * 1.2\n",
    "    y_min = min(-0.02, delta_df[delta_col].min() * 1.2)\n",
    "    \n",
    "    if abs(y_max) < 0.01:\n",
    "        y_max = max(0.01, y_max)\n",
    "    if abs(y_min) < 0.01:\n",
    "        y_min = min(-0.01, y_min)\n",
    "    \n",
    "    for i, base_model in enumerate(base_models):\n",
    "        model_data = delta_df[delta_df['base_model'] == base_model]\n",
    "        if model_data.empty:\n",
    "            continue\n",
    "            \n",
    "        refiners = sorted(model_data['refiner_model'].unique())\n",
    "        \n",
    "        x = np.arange(len(refiners))\n",
    "        \n",
    "        delta_values = []\n",
    "        for refiner in refiners:\n",
    "            refiner_data = model_data[model_data['refiner_model'] == refiner]\n",
    "            if not refiner_data.empty:\n",
    "                delta_values.append(refiner_data[f'delta_{sentiment_type}'].values[0])\n",
    "            else:\n",
    "                delta_values.append(0)\n",
    "        \n",
    "        bars = axes[i].bar(x, delta_values, 0.7, \n",
    "                         color=color, \n",
    "                         edgecolor='black', \n",
    "                         linewidth=0.5)\n",
    "        \n",
    "        for j, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            \n",
    "            if height >= 0:\n",
    "                va = 'bottom'\n",
    "                offset = 3\n",
    "            else:\n",
    "                va = 'top'\n",
    "                offset = -9\n",
    "                \n",
    "            if abs(height) < 0.001:\n",
    "                label = f'{height * 100:+.3f}%'\n",
    "                fontsize = 8\n",
    "            else:\n",
    "                label = f'{height * 100:+.1f}%'\n",
    "                fontsize = 9\n",
    "                \n",
    "            axes[i].annotate(label,\n",
    "                           xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                           xytext=(0, offset), \n",
    "                           textcoords=\"offset points\",\n",
    "                           ha='center', \n",
    "                           va=va,\n",
    "                           fontsize=fontsize)\n",
    "        \n",
    "        axes[i].axhline(y=0, color='black', linestyle='-', alpha=0.3, linewidth=0.8)\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.3, axis='y')\n",
    "        axes[i].yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=1))\n",
    "        \n",
    "        axes[i].set_ylim(-0.16, 0.16)\n",
    "        \n",
    "        axes[i].set_xticks(x)\n",
    "        axes[i].set_xticklabels(refiners, rotation=0, ha='center', fontsize=9)\n",
    "        \n",
    "        axes[i].set_title(base_model, fontsize=11, fontweight=\"bold\")\n",
    "    \n",
    "    axes[0].set_ylabel(f'Relative Change', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path_png = os.path.join(output_dir, f\"{sentiment_type}_sentiment_sidebyside.png\")\n",
    "    \n",
    "    plt.savefig(output_path_png, format='png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    method_filepath = \"../output/sentiment_distribution\"\n",
    "    base_llama3b = \"../output/llama3b_sentiment/sentiment_base_llama3b.json\"\n",
    "    base_llama8b = \"../output/llama3b_sentiment/sentiment_base_llama8b.json\"\n",
    "    \n",
    "    results_df = load_and_process_sentiment_data(method_filepath, base_llama3b, base_llama8b)\n",
    "    \n",
    "    negative_color = '#B3003F'  # Burgundy red\n",
    "    positive_color = '#006C3B'  # Forest green\n",
    "    neutral_color = '#474C55'   # Slate gray\n",
    "    \n",
    "    create_sentiment_visualization(results_df, 'neg', negative_color, \"output/sentiment\")\n",
    "    create_sentiment_visualization(results_df, 'pos', positive_color, \"output/sentiment\")\n",
    "    create_sentiment_visualization(results_df, 'neu', neutral_color, \"output/sentiment\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "a8e55c1f4c2db8f8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
