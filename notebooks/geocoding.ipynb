{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "\n",
    "from geopandas.tools import geocode\n",
    "from geopy.geocoders import Nominatim\n",
    "from rapidfuzz import fuzz\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Wrapper Methods\n",
    "# -------------------------------------------------------------------\n",
    "def retry(retries: int = 3, delay: int = 2):\n",
    "    \"\"\"\n",
    "    Decorator to retry the wrapped function upon exception.\n",
    "\n",
    "    Parameters:\n",
    "        retries (int): Number of attempts before giving up.\n",
    "        delay (int): Delay (in seconds) between attempts.\n",
    "\n",
    "    Returns:\n",
    "        A decorator that retries the function call.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            attempt = 0\n",
    "            while attempt < retries:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    print(f\"Attempt {attempt + 1} failed in {func.__name__}: {e}\")\n",
    "                    attempt += 1\n",
    "                    time.sleep(delay)\n",
    "            # Return fallback values after all retries fail.\n",
    "            return (None, None, None)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def timeit(func):\n",
    "    \"\"\"\n",
    "    Decorator to measure and print the execution time of a function.\n",
    "    \n",
    "    Returns:\n",
    "        The decorated function.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "            start_time = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            if not hasattr(wrapper, \"has_printed_header\"):\n",
    "                print(f\"+{'-'*30}+{'-'*20}+\")\n",
    "                print(f\"| {'Function':<28} | {'Execution Time':<16} |\")\n",
    "                print(f\"+{'-'*30}+{'-'*20}+\")\n",
    "                wrapper.has_printed_header = True\n",
    "            print(f\"| {func.__name__:<28} | {execution_time:.4f} seconds{'':<5} |\")\n",
    "            print(f\"+{'-'*30}+{'-'*20}+\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Geocoding of Port data\n",
    "# -------------------------------------------------------------------\n",
    "class PortGeoCoding:\n",
    "    \"\"\"\n",
    "    A class for geocoding ports from a CSV database.\n",
    "\n",
    "    This class loads port data, enriches it with primary and backup geo queries,\n",
    "    and provides methods for retrieving a DataFrame containing Port, Country,\n",
    "    Longitude, and Latitude. Geocoding is performed using Nominatim via geopy,\n",
    "    with retry logic, timing reports, and fuzzy matching to verify that the\n",
    "    returned country matches the expected country.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the PortGeoCoding instance by reading the CSV file.\n",
    "\n",
    "        Parameters:\n",
    "            csv_path (str): The path to the CSV file containing port data.\n",
    "        \"\"\"\n",
    "        self._ports = pd.read_csv(csv_path)\n",
    "        self._enrich_ports()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _serializer(df: pd.DataFrame, file_name: str, file_format: str = None) -> None:\n",
    "        \"\"\"\n",
    "        Export the provided DataFrame to a file in the designated export directory.\n",
    "    \n",
    "        This function checks for the existence of a directory named \"datasets_processed\"\n",
    "        in the current directory or in the parent directory. If the directory exists, it is\n",
    "        used; otherwise, the directory is created in the current directory. The DataFrame is\n",
    "        then exported to a file with the specified file name and format in that directory.\n",
    "        \n",
    "        The export format can be Excel, CSV, or JSON. The format is determined by:\n",
    "          - The file extension in 'file_name' (e.g., \".xlsx\", \".csv\", \".json\"), or\n",
    "          - The explicit 'file_format' parameter if provided.\n",
    "          \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The DataFrame to be exported.\n",
    "            file_name (str): The name of the output file (e.g., \"output.xlsx\", \"output.csv\", or \"output.json\").\n",
    "            file_format (str, optional): The format to export to (\"excel\", \"csv\", or \"json\"). \n",
    "                                         If not provided, the format is inferred from the file extension.\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if os.path.exists(\"datasets_processed\"):\n",
    "            export_dir = \"datasets_processed\"\n",
    "\n",
    "        elif os.path.exists(\"../datasets_processed\"):\n",
    "            export_dir = \"../datasets_processed\"\n",
    "\n",
    "        else:\n",
    "            export_dir = \"datasets_processed\"\n",
    "            os.makedirs(export_dir, exist_ok=True)\n",
    "        \n",
    "        if file_format is None:\n",
    "            file_format = file_name.split('.')[-1].lower()\n",
    "        \n",
    "        file_path = os.path.join(export_dir, file_name)\n",
    "        \n",
    "        if file_format in ['xlsx', 'excel']:\n",
    "            df.to_excel(file_path, index=True)\n",
    "\n",
    "        elif file_format == 'csv':\n",
    "            df.to_csv(file_path, index=True)\n",
    "\n",
    "        elif file_format == 'json':\n",
    "            df.to_json(file_path, orient='records', lines=True)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
    "        \n",
    "    def _is_country_match(self, expected: str, returned: str, threshold: int = 80) -> bool:\n",
    "        \"\"\"\n",
    "        Checks whether the expected country and the returned country match.\n",
    "        It first normalizes the returned country. Then it uses fuzzy matching\n",
    "        (via RapidFuzz) to compute a similarity score. If the score is above\n",
    "        the threshold, they are considered a match.\n",
    "\n",
    "        Parameters:\n",
    "            expected (str): The expected country (e.g., from the CSV).\n",
    "            returned (str): The country returned by the geocoder.\n",
    "            threshold (int): The minimum similarity percentage required.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the countries match (fuzzily); False otherwise.\n",
    "        \"\"\"\n",
    "        expected = expected.strip().lower()\n",
    "        returned = returned.strip().lower()\n",
    "        \n",
    "        special_cases = {\n",
    "            \"korea\": \"south korea\",\n",
    "            \"usa\": \"united states\",\n",
    "            \"hong kong\": \"china\"\n",
    "        }\n",
    "    \n",
    "        expected = special_cases.get(expected, expected)\n",
    "        returned = special_cases.get(returned, returned)\n",
    "            \n",
    "        score = fuzz.ratio(expected, returned)\n",
    "        return score >= threshold\n",
    "\n",
    "    def _enrich_ports(self):\n",
    "        \"\"\"\n",
    "        Enriches the ports DataFrame by adding:\n",
    "          - 'Geo_Query': A primary query built from 'Port Name' and 'Country'.\n",
    "          - 'Backup_Queries': A list of backup queries parsed from 'Also known as'.\n",
    "        \"\"\"\n",
    "        self._ports[\"Geo_Query\"] = self._ports.apply(\n",
    "            lambda row: f'{row[\"Port Name\"].title().replace(\"Anch\", \"\").strip()}, '\n",
    "                        f'{row[\"Country\"].title()}', axis=1\n",
    "        )\n",
    "        self._ports[\"Backup_Queries\"] = self._ports.apply(self.get_backup_queries, axis=1)\n",
    "\n",
    "    def get_backup_queries(self, row: pd.Series) -> list:\n",
    "        \"\"\"\n",
    "        Generates backup geo queries from a row using the 'Also known as' field.\n",
    "\n",
    "        Parameters:\n",
    "            row (pd.Series): A row from the ports DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of backup query strings.\n",
    "        \"\"\"\n",
    "        backup_queries = []\n",
    "        aka = row.get(\"Also known as\", \"\")\n",
    "        if pd.isna(aka) or not aka.strip():\n",
    "            return backup_queries\n",
    "\n",
    "        try:\n",
    "            alt_names = ast.literal_eval(aka)\n",
    "            if not isinstance(alt_names, list):\n",
    "                alt_names = [alt_names]\n",
    "                \n",
    "        except Exception:\n",
    "            alt_names = [aka]\n",
    "\n",
    "        for alt in alt_names:\n",
    "            alt_clean = alt.strip()\n",
    "            if alt_clean and alt_clean != '-':\n",
    "                backup_queries.append(f\"{alt_clean.title().replace('Anch', '').strip()}\"\n",
    "                                      f\", {row['Country'].title()}\")\n",
    "        return backup_queries\n",
    "\n",
    "    @retry(retries=3, delay=1)\n",
    "    def get_coordinates(self, in_location: str, silent: bool = True) -> (float, float, str):\n",
    "        \"\"\"\n",
    "        Retrieves the latitude, longitude, and country for a given location using Nominatim.\n",
    "\n",
    "        Parameters:\n",
    "            in_location (str): The location query string.\n",
    "            silent (bool):     Surpresses prints, defaults to True.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (latitude, longitude, country) if found, otherwise (None, None, None).\n",
    "        \"\"\"\n",
    "        geolocator = Nominatim(user_agent=\"port_geo_coding\")\n",
    "        location = geolocator.geocode(in_location, addressdetails=True, language=\"en\")\n",
    "        if location is not None:\n",
    "            address = location.raw.get('address', {})\n",
    "            country = address.get('country', None)\n",
    "        else:\n",
    "            country = None\n",
    "        \n",
    "        if not silent:\n",
    "            print(f\"+{'-'*30}+{'-'*30}+\")\n",
    "            print(f\"| {'Input Location':<28} | {'Mapped Country':<28} |\")\n",
    "            print(f\"+{'-'*30}+{'-'*30}+\")\n",
    "            print(f\"| {in_location:<28} | {country if country else 'None':<28} |\")\n",
    "            print(f\"+{'-'*30}+{'-'*30}+\")\n",
    "            \n",
    "        if not location:\n",
    "            return (None, None, None)\n",
    "        \n",
    "        return (location.latitude, location.longitude, country)\n",
    "\n",
    "    @timeit\n",
    "    def yield_geocoded_ports(self, export: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Geocodes each port and returns a DataFrame with 'Port', 'Country', 'Longitude', and 'Latitude'.\n",
    "\n",
    "        For each port, the method:\n",
    "          1. Attempts geocoding using the primary 'Geo_Query'.\n",
    "          2. Validates the result by ensuring coordinates are present and that the\n",
    "             returned country (after normalization) fuzzily matches the expected country.\n",
    "          3. If invalid, iterates over backup queries until a valid result is found.\n",
    "          4. If no valid result is found, leaves the coordinates as None.\n",
    "        \n",
    "        Parameters:\n",
    "            export (bool): Indicator whether the computed dataframe shall be exported\n",
    "                           defaults to True (meaning gets exported to an excel file).\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing geocoded port data.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for idx, row in self._ports.iterrows():\n",
    "            expected_country = row[\"Country\"].title()\n",
    "            primary_query = row[\"Geo_Query\"]\n",
    "            lat, lon, country = self.get_coordinates(primary_query)\n",
    "            \n",
    "            valid = True\n",
    "            if lat is None or lon is None or country is None:\n",
    "                valid = False\n",
    "            else:\n",
    "\n",
    "                if not self._is_country_match(expected_country, country):\n",
    "                    valid = False\n",
    "            \n",
    "            if not valid:\n",
    "                for backup in row[\"Backup_Queries\"]:\n",
    "                    lat, lon, country = self.get_coordinates(backup)\n",
    "                    if lat is not None and lon is not None and country is not None:\n",
    "                        if self._is_country_match(expected_country, country):\n",
    "                            valid = True\n",
    "                            break\n",
    "                        else:\n",
    "                            valid = False\n",
    "            \n",
    "            results.append({\n",
    "                \"Port\": row[\"Port Name\"].title().replace(\"Anch\", \"\").strip(),\n",
    "                \"Country\": expected_country,\n",
    "                \"Longitude\": lon,\n",
    "                \"Latitude\": lat\n",
    "            })\n",
    "        \n",
    "        df_geocoded = pd.DataFrame(results)\n",
    "        \n",
    "        if export:\n",
    "            self._serializer(df=df_geocoded, file_name=\"port_data_geocoded.xlsx\", file_format=\"xlsx\")\n",
    "                \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    def _haversine(self, lon1: float, lat1: float, lon2: float, lat2: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the great-circle distance between two points on the Earth\n",
    "        specified in decimal degrees using the Haversine formula.\n",
    "        \n",
    "        Parameters:\n",
    "            lon1 (float): Longitude of the first point.\n",
    "            lat1 (float): Latitude of the first point.\n",
    "            lon2 (float): Longitude of the second point.\n",
    "            lat2 (float): Latitude of the second point.\n",
    "        \n",
    "        Returns:\n",
    "            float: Distance between the two points in kilometers.\n",
    "        \"\"\"\n",
    "        lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n",
    "        \n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        \n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "        c = 2 * math.asin(math.sqrt(a))\n",
    "        \n",
    "        r = 6371\n",
    "        return c * r\n",
    "    \n",
    "    def compute_distance_matrix(self, df: pd.DataFrame, export: bool = True)-> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Computes the distance matrix for all ports covered based on the\n",
    "        haversince distance.\n",
    "        \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): The plain port dataframe containing long and lat data.\n",
    "            export (bool):     Indicator whether the computed dataframe shall be exported\n",
    "                               defaults to True (meaning gets exported to an excel file).\n",
    "                               \n",
    "        Returns:\n",
    "            pd.DataFrame: The distance matrix.\n",
    "        \"\"\"\n",
    "        df = df.dropna(subset=[\"Longitude\", \"Latitude\"]).reset_index()\n",
    "        \n",
    "        num_ports = df.shape[0]\n",
    "        \n",
    "        distance_matrix = np.zeros((num_ports, num_ports))\n",
    "        \n",
    "        for i in range(num_ports):\n",
    "            for j in range(i, num_ports):\n",
    "                lon1, lat1 = df.loc[i, 'Longitude'], df.loc[i, 'Latitude']\n",
    "                lon2, lat2 = df.loc[j, 'Longitude'], df.loc[j, 'Latitude']\n",
    "                distance = self._haversine(lon1, lat1, lon2, lat2)\n",
    "                distance_matrix[i, j] = distance\n",
    "                distance_matrix[j, i] = distance\n",
    "        \n",
    "        distance_df = pd.DataFrame(distance_matrix, \n",
    "                                   index=df['Port'], \n",
    "                                   columns=df['Port'])\n",
    "        \n",
    "        if export:\n",
    "            self._serializer(df=distance_df, file_name=\"distance_matrix.xlsx\", file_format=\"xlsx\")\n",
    "        \n",
    "        return distance_df\n",
    "        \n",
    "    def visualize_ports(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Visualize port locations on a world map and export the resulting image.\n",
    "    \n",
    "        This function takes a DataFrame with port data that includes at least the following columns:\n",
    "          - 'Longitude': The longitude of the port.\n",
    "          - 'Latitude': The latitude of the port.\n",
    "          - 'Country': The country in which the port is located.\n",
    "          \n",
    "        The function performs the following steps:\n",
    "          1. Loads a base world map using Natural Earth's low-resolution dataset.\n",
    "          2. Converts the port coordinates into a GeoDataFrame.\n",
    "          3. Determines which countries have at least one port data point and lightly shades those countries.\n",
    "          4. Plots the world map, the shaded countries, and overlays the port locations with custom styling.\n",
    "          5. Adds a title, axis labels, grid, legend, and other stylistic elements.\n",
    "          6. Exports the final visualization to a PNG file in an \"exports\" directory. The directory is searched for in\n",
    "             the current directory and its parent; if not found, an \"exports\" directory is created in the current directory.\n",
    "          7. Displays the final plot.\n",
    "    \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): A DataFrame containing the port data with the columns 'Longitude', 'Latitude', and 'Country'.\n",
    "    \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "        \n",
    "        gdf_ports = gpd.GeoDataFrame(\n",
    "            df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude)\n",
    "        )\n",
    "        \n",
    "        port_countries = df[\"Country\"].unique()\n",
    "        \n",
    "        mapping = {\n",
    "            'usa': 'United States of America',\n",
    "            'korea': 'South Korea'\n",
    "        }\n",
    "        \n",
    "        port_countries_adjusted = [mapping.get(country.lower(), country) for country in port_countries]\n",
    "        mask = world['name'].str.lower().isin([c.lower() for c in port_countries_adjusted])\n",
    "        \n",
    "        shaded_countries = world[mask]\n",
    "        \n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(25, 16))\n",
    "        \n",
    "        world.plot(ax=ax, color='#f5f5f5', edgecolor='#bdbdbd')\n",
    "        \n",
    "        shaded_countries.plot(ax=ax, color='#d1e5f0', edgecolor='#bdbdbd', alpha=0.8)\n",
    "        \n",
    "        gdf_ports.plot(\n",
    "            ax=ax,\n",
    "            marker='o',\n",
    "            color='red',\n",
    "            markersize=80,\n",
    "            alpha=0.85,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5,\n",
    "            label='Port'\n",
    "        )\n",
    "        \n",
    "        title_text = 'Port Locations'\n",
    "        ax.set_title(title_text, fontsize=28, fontweight='bold', pad=20)\n",
    "        ax.set_xlabel('Longitude', fontsize=18)\n",
    "        ax.set_ylabel('Latitude', fontsize=18)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        port_marker = mlines.Line2D([], [], color='red', marker='o',\n",
    "                                    linestyle='None', markersize=10, label='Port')\n",
    "        \n",
    "        ax.legend(handles=[port_marker], fontsize=16, loc='upper left')\n",
    "        \n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if os.path.exists(\"exports\"):\n",
    "            export_dir = \"exports\"\n",
    "            \n",
    "        elif os.path.exists(\"../exports\"):\n",
    "            export_dir = \"../exports\"\n",
    "            \n",
    "        else:\n",
    "            export_dir = \"exports\"\n",
    "            os.makedirs(export_dir, exist_ok=True)\n",
    "        \n",
    "        export_path = os.path.join(export_dir, \"port_locations.png\")\n",
    "        plt.savefig(export_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()    "
   ],
   "id": "ccdd85259146bc8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "csv_file = \"../data/port_data/shipping_ports_around_the_world/port_data.csv\"\n",
    "port_geocoder = PortGeoCoding(csv_file)\n",
    "\n",
    "df_geo = port_geocoder.yield_geocoded_ports()\n",
    "port_geocoder.compute_distance_matrix(df_geo)"
   ],
   "id": "e4fd6e505d2db43f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
